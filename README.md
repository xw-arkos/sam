# Sam
Sam will be an autonomous AI agent built with the intention of working seamlessly with users as if they were human. Imagine this scenario, as a developer, you are given requirements and problems for a project you to working on. You are expected to find the best solution either by yourself or with a team, you instead discuss with or involve Sam in discussion, who in turn contributes to the solution. In a sprint environment, Sam would be asynchronously programming with you. Sam would be able to edit the same files you are working on (imagine google docs). Sam would be able to search the web, research, and present to you relevant resources when requested without pulling you from your IDE. This workflow with Sam differs from Co-pilot and ChatGPT, because Sam works asynchronously with you as if they were another person as opposed to forcing you to wait for code completions to be completed by Co-pilot. 

The benefits of Sam can be extended to other roles:
1. Business Analysts. Imagine a pocket assistant that is always on the same page as you. They are able to understand APIs. They can proof read and contribute to requirement documentation. 
2. Managers. Imagine a 2IC that you can rely on and appoint tasks to. They can manage your resources on your behalf. They can read, write, and monitor emails on your behalf. They can notify you of any business-critical emails, tasks, or cases.


The key takeaways are:
1. Sam is a standin for a huamn worker. 
2. You will be able to work with and delegate tasks to Sam without being taken out of your own flow.
3. Sam would be on the same page as you. You should never need to reiterate context of the task or problem to Sam. Sam should always be involved with you at every stage and hence would always have an understanding of the context.


## Technical
Input -> Brain -> Output
            ==> Memory
            ==> Skills

Key: -> Flow
     => Side effects

We define different sources of inputs that supply information in a common medium to the Brain.
We define different methods of output or methods for how the LLM responds.

In processing the I/O, memory and skills are produced as side effects to enrich future I/O.
Memory provides long and short term context to the inputs.
Skills are resuable components developed by the LLM. These could be executable code. Resuable apps or mini LLMs. The key is they are resuable, are auto-developed by the LLM (developers can create their own to fast-track capabilities).

Strings would be the medium of communicating information from input to output.


## Outcomes
### Stage 1
1. Voice
  - Speech to text (Microphone input)
  - Text to speech
2. Text file inputs
3. Brain (LLM, prompting, and agent flows)
4. Can edit files, files the user has open, and closed files


### Future
1. Skills development
2. Self code creation and execution


## Roadmap
Stage 1 - End of November (30th Nov 2023)
